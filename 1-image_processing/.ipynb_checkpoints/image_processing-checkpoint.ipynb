{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to CS6475 Computational Photography\n",
    "---\n",
    "This notebook introduces some key aspects of the numpy and OpenCV APIs as they relate to image manipulation. These techniques are building blocks that can be used extensively throughout the course. There are no deliverables for this **optional** exercise, but you are free to discuss on the forums, and the material covered may appear on the final exam.\n",
    "\n",
    "You should complete Parts 1-3 by reading through the notebook and executing each code cell (you can use the keyboard shortcut `shift + enter` to execute cells). After completing the tutorial, you can check your understanding by using what you've learned to complete a series of challenges where you are asked to implement some more complex functions like automatic contrast adjustment for color images and writing your own Canny edge detector. You are **not** required to complete the challenges, but they are designed to help prepare you for later topics in the course.\n",
    "\n",
    "## Lesson Summary\n",
    "---\n",
    "  - [Part 1 - Image I/O](#Part-1---Image-I/O) -- introduce basic file I/O in OpenCV\n",
    "  - [Part 2 - Image Objects](#Part-2:-Image-Objects) -- explore the API available on images\n",
    "  - [Part 3 - Image Manipulation](#Part-3:-Image-Manipulation) -- demonstrate fundamental image manipulation operators\n",
    "  - [Part 4 - Challenges](#Part-4:-Challenges) -- apply what you've learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use jupyter \"magic\" methods to dynamically reload external modules every\n",
    "# time any block is run, and show images inline in the notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1 - Image I/O\n",
    "---\n",
    "**Key Questions:**\n",
    "  - What happens when the name of the image file doesn't exist? Does OpenCV raise an error? What value does the variable take?\n",
    "  - What happens if you don't specify a file extension when writing an image file to disk?\n",
    "  - What is the default color space for images in OpenCV?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Read & display a grayscale image\n",
    "---\n",
    "**Example:** Read & display a sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gray_img = cv2.imread(\"example.png\", cv2.IMREAD_GRAYSCALE)\n",
    "plt.imshow(gray_img, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"Grayscale Buzz\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Read & display a color image\n",
    "---\n",
    "**Example:** Read & display a sample image in color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "color_img = cv2.imread(\"example.png\", cv2.IMREAD_COLOR)\n",
    "plt.imshow(color_img); plt.axis(\"off\"); plt.title(\"Color Buzz\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something doesn't look right about that picture though. The color seems wrong -- buzz should be **yellow**, not blue. The `imshow()` function expects images to be in [Red, Green, Blue] (i.e., **RGB**) color space, but OpenCV uses [Blue, Green, Red] order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# modify array shape from (row, col, channel) --> (channel, row, col) and use python multiple-assignment semantics\n",
    "# to extract the color channels; `channels` is an array, while `blue`, `green`, and `red` each hold one channel\n",
    "channels = blue, green, red = np.rollaxis(color_img, 2)\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(131); plt.imshow(channels[0], cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"Blue Channel\");\n",
    "plt.subplot(132); plt.imshow(channels[1], cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"Green Channel\");\n",
    "plt.subplot(133); plt.imshow(channels[2], cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"Red Channel\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Read & display a color image (correctly this time)\n",
    "---\n",
    "  - Use the cv2.cvtColor function for simplicity, or to apply more complex color space transformations (BGR2RGB, RGB2GRAY, YCrCv, HSV, etc.)\n",
    "\n",
    "**See Also:** [cv2.cvtColor()](http://docs.opencv.org/2.4/modules/imgproc/doc/miscellaneous_transformations.html), [np.hstack()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.hstack.html), [np.vstack()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.vstack.html), [np.dstack()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.dstack.html)\n",
    "\n",
    "**Example:** Correct the color channel order of an image and display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rgb_img = np.dstack([red, green, blue])  # recombine the color channels (there are more efficient ways than this)\n",
    "# rgb_img = cv2.cvtColor(color_img, cv2.COLOR_BGR2RGB)  # same as above\n",
    "plt.imshow(rgb_img); plt.axis(\"off\"); plt.title(\"Color Buzz (Corrected)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 4 Save an image to disk\n",
    "---\n",
    "OpenCV infers the encoding from the filename extension; you can use jpg, jpeg, bmp, png, tif, and tiff.\n",
    "\n",
    "**See Also:** [cv2.imwrite()](http://docs.opencv.org/2.4/modules/highgui/doc/reading_and_writing_images_and_video.html#imwrite)\n",
    "\n",
    "**Example:** Save each of the three color channels as grayscale images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.imwrite(\"blue.png\", blue)\n",
    "cv2.imwrite(\"green.png\", green)\n",
    "cv2.imwrite(\"red.png\", red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Image Objects\n",
    "---\n",
    "In this section we will demonstrate the API for image objects. When finished, you should be able to answer the following questions:\n",
    "\n",
    "**Key Questions:**\n",
    "  - What is the type of image objects read with OpenCV? What is the default \"dtype\" of images?\n",
    "  - What kind of operations can be performed on images?\n",
    "  - What is \"broadcasting\"?\n",
    "  - What is overflow/underflow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(\"example.png\", cv2.IMREAD_GRAYSCALE)  # reload the sample image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Type Information & Basic Attributes\n",
    "---\n",
    "\n",
    "Images are stored as [multidimensional arrays](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html). By default, pixels are treated as [unsigned 8-bit integers](https://docs.scipy.org/doc/numpy/user/basics.types.html) with a range of [0-255]. The array objects have tons of useful attributes and methods, and you will almost always get better performance from built-in functions than writing your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show the type information for an array\n",
    "print \"Image type:\", type(img)\n",
    "print \"Pixels are represented by unsigned 8-bit values:\", img.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example ndarray object properties\n",
    "img_dims = img.ndim\n",
    "img_shape = img.shape\n",
    "img_size = img.size\n",
    "\n",
    "print \"\\n{:^70}\".format(\"NDARRAY ATTRIBUTES\")\n",
    "print \"{:^70}\\n\".format(\"====================\")\n",
    "print \"{:^30}{:^20}{:^20}\".format(\"Description\", \"Example\", \"Value\")\n",
    "print \"{:^30}{:^20}{:^20}\".format(\"-------------\", \"---------\", \"-------\")\n",
    "print \"{:^30}{:^20}{:^20}\".format(\"Number of dimensions\", \"img.ndim\", img_dims)\n",
    "print \"{:^30}{:^20}{:^20}\".format(\"Image Shape\", \"img.shape\", img_shape)\n",
    "print \"{:^30}{:^20}{:^20}\".format(\"Pixel count\", \"img.size\", img_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Basic Array Indexing & Slicing\n",
    "---\n",
    "Numpy arrays support both basic and \"advanced\" [indexing & slicing](https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html). There are terse statements to get each row, column, element, or rectangular subarrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Basic Indexing\n",
    "  - `ndarrays` can be treated just like multidimensional arrays. `img[i][j]` returns the element in row i, column j. Additional array dimensions follow the same pattern, e.g., `img[i][j][k]` for 3d arrays.\n",
    "\n",
    "**Example:** Get the pixel value at row 37, column 73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img[37][73]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Better Indexing\n",
    "\n",
    "  - Although you _can_ use multiple slices for each axis, it is better to combine the indices to a single slice; using multiple slices incurs the overhead of parsing the indexes for every pair of brackets.\n",
    "\n",
    "**Example:** Get the same pixel as 2.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img[37, 73]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Indexing a subarray\n",
    "\n",
    "  - `ndarray` indexes support array slice syntax `start:end:step` for each axis.\n",
    "\n",
    "**Example:** Grab a 3x4 region from the top-right corner of the sample image (the first 3 rows, last 4 columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img[0:3, img.shape[1]-4:img.shape[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Advanced slicing\n",
    "\n",
    "  - Slice indices can be simplified by omitting leading 0 if the slice starts from the beginning of that dimension, it can ommit the last index if the slice ends at the end of that dimension, and it supports positive and negative indexing.\n",
    "\n",
    "**Example:** Simplify the example from 2.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img[:3, -4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - The `:` symbol means \"all\" for a particular axis.\n",
    "\n",
    "**Example:** Grab the first row or first column of the sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Original img.shape:\", img.shape\n",
    "print \"Shape of the first column of pixels (all rows, column 0): \", img[:, 0].shape\n",
    "print \"Shape of the first row of pixels (row 0, all columns): \", img[0, :].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 \"Advanced\" Indexing\n",
    "---\n",
    "Advanced slicing & indexing makes these arrays incredibly powerful, and allows writing fast, concise code. The speed comes from leveraging the compiled C extensions of the Numpy library instead of pure Python. The same syntax used for basic indexing can be used to select arbitrary elements by coordinates, with boolean indexing, or by linear index.\n",
    "\n",
    "#### 2.3.1 Specifying a list of coordinates\n",
    "\n",
    "  - You can pass a list of coordinates for each element you want to extract. (Note that this returns a 1-d array of elements.)\n",
    "\n",
    "**See also:** [np.where()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.where.html), [np.argwhere()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argwhere.html)\n",
    "\n",
    "**Example:** Grab pixels at even rows and odd columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Index arrays\n",
    "rows = [0, 2, 4, 6, 8]\n",
    "cols = [1, 3, 5, 7, 9]\n",
    "print \"rows =\", rows\n",
    "print \"cols =\", cols\n",
    "print \"img[rows, cols]: \", img[rows, cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Using a boolean mask\n",
    "\n",
    "  - You can pass in an array of the same shape (subject to broadcasting rules) where each element that is True in the mask will appear in the output. (Note that this returns a 1-d array of elements.)\n",
    "  \n",
    "**Example:** Get the pixel intensities from the first 3 rows and 4 columns in the sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = np.zeros(img.shape, dtype=bool)\n",
    "mask[:3, :4] = True\n",
    "img[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - You can also construct a boolean array from an expression (following array broadcasting rules) to use as an index. (Note that this returns a 1-d array.)\n",
    "  \n",
    "**Example:** Find all the pixels in the sample image with an intensity >230"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img[img > 230]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Array methods\n",
    "---\n",
    "[`ndarray`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html) objects have many convenient methods & properties (see docs for list). Many of these methods accept optional keyword arguments `axis` and/or `dtype` that change the accumulator type and allow the operation to be perfomed along each row or column instead of the entire matrix.\n",
    "\n",
    "#### 2.4.1 Basic methods\n",
    "\n",
    "**Example:** Get the minimum, maximum, mean, and sum of all values in an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Minimum pixel intensity:\", img.min()\n",
    "print \"Maximum pixel intensity:\", img.max()\n",
    "print \"Mean pixel intensity:\", img.mean()\n",
    "print \"Cumulative pixel intensity:\", img.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** Use the `axis` and `dtype` keyword arguments to find the maximum sum of any column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"maximum column sum:\", img.sum(axis=0, dtype=float).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 Advanced array manipulation - Type Casting\n",
    "\n",
    "**See Also:** [numpy data types](https://docs.scipy.org/doc/numpy/user/basics.types.html)\n",
    "\n",
    "**Example:** Use numpy utility functions to change the array data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert from uint8 -> float64, use .astype()\n",
    "img64 = img.astype(np.float64)\n",
    "print \"old dtype:\", img.dtype\n",
    "print \"new dtype:\", img64.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.3 Advanced array manipulation - Changing Array Shape\n",
    "\n",
    "**See Also:** [np.reshape()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html), [np.atleast_2d()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.atleast_2d.html), [np.atleast_3d()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.atleast_3d.html), [np.ravel()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ravel.html), [np.rollaxis()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.rollaxis.html), [np.swapaxes()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.swapaxes.html), [np.newaxis](https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html#numpy.newaxis)\n",
    "\n",
    "**Example:** Use numpy utility functions to change the array data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img3d = np.atleast_3d(img)  # equivalent to img[:, :, np.newaxis]\n",
    "print \"old shape:\", img.shape\n",
    "print \"new shape:\", img3d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Arithmetic & Broadcasting\n",
    "---\n",
    "Python supports operator overloading, so ndarrays perform element-wise arithmetic using the `+ - * /` operators. These operators also support [\"broadcasting\"](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html), which allows extraordinary flexibility when used properly. Here is a great resource on broadcasting: http://scipy.github.io/old-wiki/pages/EricsBroadcastingDoc\n",
    "\n",
    "> The basic broadcasting rule is that two arrays are compatible if the dimension of the trailing axes of both arrays match, or if one of them is one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "color_img = cv2.imread(\"example.png\", cv2.IMREAD_COLOR)  # reload the sample image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.1 Arithmetic Overflow & Underflow\n",
    "\n",
    "Images are treated just like arrays, so they support all the \"usual\" arithmetic operations. But representing pixel values with fixed-width precision data types creates precision errors. By default, pixels are uint8's that are limited to the range [0-255], so things break when values from a calculation fall outside that range.\n",
    "\n",
    "**Example:** Use the color channels of the image to experiment with the sum, product, and difference of arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bluePlusGreen = color_img[:, :, 0] + color_img[:, :, 1]\n",
    "redTimesBlue = color_img[:, :, 2] * color_img[:, :, 0]\n",
    "greenMinusRed = color_img[:, :, 1] - color_img[:, :, 2]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(131); plt.imshow(bluePlusGreen, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"Sum\");\n",
    "plt.subplot(132); plt.imshow(redTimesBlue, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"Product\");\n",
    "plt.subplot(133); plt.imshow(greenMinusRed, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"Difference\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.2 Typecasting\n",
    "The good news is that in most cases you can fix the problem by simply casting the image dtype to higher precision.\n",
    "\n",
    "OpenCV also offers functions for most arithmetic operations (e.g., cv2.add, cv2.addWeighted, etc.), and it is worth noting that numpy and OpenCV do not handle overflow the same way. OpenCV clamps at the min and max value for the precision (128 + 128 == min(128 + 128, 255)); numpy operators wrap (128 + 128 == (128 + 128) % 256).\n",
    "\n",
    "\n",
    "**Example:** Fix the previous example by casting the values to 64-bit floats first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_img = color_img.astype(float)\n",
    "bluePlusGreen = _img[:, :, 0] + _img[:, :, 1]\n",
    "redTimesBlue = _img[:, :, 2] * _img[:, :, 0]\n",
    "greenMinusRed = _img[:, :, 1] - _img[:, :, 2]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(131); plt.imshow(bluePlusGreen, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"Sum\");\n",
    "plt.subplot(132); plt.imshow(redTimesBlue, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"Product\");\n",
    "plt.subplot(133); plt.imshow(greenMinusRed, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"Difference\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Image Manipulation\n",
    "---\n",
    "**Key Questions:**\n",
    "  - What is the difference between `np.diff`, `np.gradient`, and `cv2.Sobel`?\n",
    "  - What is the relationship between aliasing and interpolation?\n",
    "  - What is the relationship between image border padding and \"boundary condition\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(\"example.png\", cv2.IMREAD_GRAYSCALE)  # reload the sample image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Basic Manipulation\n",
    "---\n",
    "**Example:** Transpose and flip an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24, 6));\n",
    "plt.subplot(141); plt.imshow(img, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"Original\");\n",
    "plt.subplot(142); plt.imshow(img.T, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"Transpose\");\n",
    "plt.subplot(143); plt.imshow(np.fliplr(img), cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"Flip Horizontal\");\n",
    "plt.subplot(144); plt.imshow(np.flipud(img), cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"Flip Vertical\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Image resizing (subsampling)\n",
    "\n",
    "The simplest method of reducing an image size is by subsampling -- dropping rows and columns until the desired scale is reached.\n",
    "\n",
    "**Example:** Compare array slicing and linear interpolation to subsample an image to 1/10 scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_img = img[::10, ::10]\n",
    "res_img = cv2.resize(img, sub_img.shape[::-1])\n",
    "plt.figure(figsize=(9, 4));\n",
    "plt.subplot(131); plt.imshow(img, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"Original\");\n",
    "plt.subplot(132); plt.imshow(sub_img, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"Subsampled\");\n",
    "plt.subplot(133); plt.imshow(res_img, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"cv2.resize - Linear\");\n",
    "print \"Original size:\", img.shape\n",
    "print \"Reduced size:\", sub_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Image resizing (interpolating)\n",
    "\n",
    "The jagged edges in the subsampled image are an artifact called \"aliasing\". It can be mitigated by smoothing (blurring) the image before subsampling, or (generally) by changing the interpolation method. The `cv2.resize` function has several interpolation methods (linear, cubic, etc.).\n",
    "\n",
    "**Example:** Use cv2.resize to avoid aliasing while downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs_img = cv2.GaussianBlur(img, ksize=(13, 13), sigmaX=2.5)[::10, ::10]\n",
    "interp_img = cv2.resize(img, sub_img.shape[::-1], interpolation=cv2.INTER_AREA)\n",
    "plt.figure(figsize=(12, 4));\n",
    "plt.subplot(141); plt.imshow(img, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"Original\");\n",
    "plt.subplot(142); plt.imshow(sub_img, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"Subsampled\");\n",
    "plt.subplot(143); plt.imshow(bs_img, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"Blur + Subsampled\");\n",
    "plt.subplot(144); plt.imshow(interp_img, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"cv2.resize - Area Interpolation\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Image Gradients\n",
    "---\n",
    "\n",
    "**See Also:** [np.diff()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.diff.html), [np.gradient()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.gradient.html), [cv2.Sobel()](http://docs.opencv.org/2.4/modules/imgproc/doc/filtering.html#sobel), [cv2.Scharr()](http://docs.opencv.org/2.4/modules/imgproc/doc/filtering.html#scharr)\n",
    "\n",
    "#### 3.2.1 Simple finite difference approximation\n",
    "\n",
    "**Example:** Calculate the first spatial derivative of an image along using finite differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dy = np.diff(img.astype(float), axis=0)  # dy\n",
    "dx = np.diff(img.astype(float), axis=1)  # dx\n",
    "plt.figure(figsize=(12, 6));\n",
    "plt.subplot(131); plt.imshow(img, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"Original\");\n",
    "plt.subplot(132); plt.imshow(dy, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"dy\");\n",
    "plt.subplot(133); plt.imshow(dx, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"dx\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Central finite difference approximation\n",
    "**Example:** Calculate the first spatial derivative of an image using the central differences approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dy, dx = np.gradient(img.astype(float))\n",
    "plt.figure(figsize=(12, 6));\n",
    "plt.subplot(131); plt.imshow(img, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"Original\");\n",
    "plt.subplot(132); plt.imshow(dy, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"dy\");\n",
    "plt.subplot(133); plt.imshow(dx, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"dx\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Sobel derivative approximation\n",
    "**Example:** Calculate the first spatial derivative of an image using the Sobel operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dy = cv2.Sobel(img, cv2.CV_64F, 0, 1)\n",
    "dx = cv2.Sobel(img, cv2.CV_64F, 1, 0)\n",
    "plt.figure(figsize=(12, 6));\n",
    "plt.subplot(131); plt.imshow(img, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"Original\");\n",
    "plt.subplot(132); plt.imshow(dy, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"dy\");\n",
    "plt.subplot(133); plt.imshow(dx, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"dx\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Border Padding\n",
    "---\n",
    "\n",
    "Pixel-level operations on images often require special-case handling near the image borders (\"edge cases\" -- _pun intended_). For example, when calculating the gradient near the edges `np.diff` uses forward finite differences which just shrinks the appropriate dimension by one, while `np.gradient` pads the border and uses a second order central difference approximation to keep the input and output shape the same. Both approaches are _valid_ in the right circumstances, but it illustrates the issue of applying appropriate padding before operating on an image.\n",
    "\n",
    "**See Also:** [np.pad](https://docs.scipy.org/doc/numpy/reference/generated/numpy.pad.html#numpy.pad), [cv2.copyMakeBorder](http://docs.opencv.org/2.4/modules/imgproc/doc/filtering.html#copymakeborder)\n",
    "\n",
    "Note: `np.pad()` is significantly more flexible than `cv2.copyMakeBorder`, but it is also significantly _slower_.\n",
    "\n",
    "**Example:** Expand an image with `cv2.BORDER_CONSTANT`, `cv2.BORDER_REFLECT`, and `cv2.BORDER_REFLECT_101` edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate a test image\n",
    "vals = cv2.getGaussianKernel(9, 1.5)\n",
    "img = (cv2.normalize(vals * np.rollaxis(vals, 1), alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)).astype(np.uint8)\n",
    "\n",
    "# make a copy of the original that shares the same scale as the outputs -- the white border\n",
    "# will not appear in the jupyter notebook\n",
    "_img = cv2.copyMakeBorder(img, 4, 4, 4, 4, borderType=cv2.BORDER_CONSTANT, value=255)\n",
    "\n",
    "#  \n",
    "zPadded = cv2.copyMakeBorder(img, 4, 4, 4, 4, borderType=cv2.BORDER_CONSTANT, value=127)\n",
    "rPadded = cv2.copyMakeBorder(img, 4, 4, 4, 4, borderType=cv2.BORDER_REFLECT)\n",
    "r101Padded = cv2.copyMakeBorder(img, 4, 4, 4, 4, borderType=cv2.BORDER_REFLECT_101)\n",
    "\n",
    "plt.figure(figsize=(12, 6));\n",
    "plt.subplot(141); plt.imshow(_img, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"Original\");\n",
    "plt.subplot(142); plt.imshow(zPadded, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"Constant Fill (127)\");\n",
    "plt.subplot(143); plt.imshow(rPadded, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"Border Reflect\");\n",
    "plt.subplot(144); plt.imshow(r101Padded, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"Border Reflect 101\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Challenges\n",
    "---\n",
    "\n",
    "Optional challenge projects to check your understanding of the numpy and openCV APIs. None of these will be graded, but the topics may appear on the final exam. You **MAY** share and discuss code for these challenge problems on the forum.\n",
    "\n",
    "### 4.1 Advanced boundary conditions\n",
    "  - Write a function to pad an image such that the first derivative at the border is zero\n",
    "  - Write a function to pad an image such that the second derivative at the border is zero\n",
    "  - In both cases, justify your choice of gradient operator (e.g., forward difference, backward difference, central difference, Sobel, etc.) under which the derivative is zero\n",
    " \n",
    "### 4.2 Local extrema\n",
    "  - Write a function to replace each pixel in an image with the local minima assuming a [4-connected neighborhood](https://en.wikipedia.org/wiki/Pixel_connectivity)\n",
    "  - Write a function to replace each pixel in an image with the local maxima assuming an [8-connected neighborhood](https://en.wikipedia.org/wiki/Pixel_connectivity)\n",
    "  \n",
    "### 4.3 DIY Image Filtering\n",
    "  - Write a function to perform 2d convolution between an image and a filter kernel using nested for loops, including appropriate border padding to match the shape of the output to the input\n",
    "  - Find the source code for `cv2.filter2D()` and compare it with your implementation\n",
    "  \n",
    "### 4.4 Image Contrast Adjustment\n",
    "  - Write a function to apply [linear scaling](https://en.wikipedia.org/wiki/Normalization_%28image_processing%29) to a grayscale image & compare it to `cv2.normalize()`\n",
    "  - Write a function to apply [histogram equalization](https://en.wikipedia.org/wiki/Histogram_equalization) to a grayscale image\n",
    "  - Extend both functions to work on color images; justify any assumptions\n",
    "\n",
    "### 4.5 Edge detection\n",
    "  - Write your own [Canny edge detector](https://en.wikipedia.org/wiki/Canny_edge_detector) and compare it with the OpenCV implementation `cv2.Canny()`"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
